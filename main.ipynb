{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mDEPRECATION: Loading egg at /Users/saikrishna/anaconda3/lib/python3.11/site-packages/chainercv-0.13.1-py3.11-macosx-11.1-arm64.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\u001b[0m\u001b[33m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install gtts librosa soundfile pydub scipy numpy -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Text-to-Audio Pipeline\n",
        "Converts text into MP3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ TextToAudioPipeline class loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from gtts import gTTS\n",
        "from typing import List, Optional\n",
        "\n",
        "\n",
        "class TextToAudioPipeline:\n",
        "    \"\"\"Pipeline for converting text to MP3 audio files.\"\"\"\n",
        "    \n",
        "    def __init__(self, output_dir: str = \"./outputs/\"):\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self._init_output_dir()\n",
        "    \n",
        "\n",
        "    def _init_output_dir(self):\n",
        "        \"\"\"Ensures the output directory exists.\"\"\"\n",
        "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "\n",
        "    def _get_unique_filename(self, base_name: str) -> str:\n",
        "        \"\"\"\n",
        "        Checks for file existence and returns a unique filename string.\n",
        "        Example: 'test' -> 'test_v1' if 'test.mp3' exists.\n",
        "        \"\"\"\n",
        "        stem = Path(base_name).stem\n",
        "        candidate_stem = stem\n",
        "        counter = 1\n",
        "        \n",
        "        while (self.output_dir / f\"{candidate_stem}.mp3\").exists() or \\\n",
        "              (self.output_dir / f\"{candidate_stem}.txt\").exists():\n",
        "            candidate_stem = f\"{stem}_v{counter}\"\n",
        "            counter += 1\n",
        "        \n",
        "        return candidate_stem\n",
        "    \n",
        "\n",
        "    def convert(self, input_text: str, output_filename: str = \"file_save\") -> Optional[Path]:\n",
        "        \"\"\"Converts text to an MP3 and saves a transcript copy.\"\"\"\n",
        "        if not input_text.strip():\n",
        "            print(\"Error: Input text is empty.\")\n",
        "            return None\n",
        "        \n",
        "        unique_stem = self._get_unique_filename(output_filename)\n",
        "        audio_path = self.output_dir / f\"{unique_stem}.mp3\"\n",
        "        text_path = self.output_dir / f\"{unique_stem}.txt\"\n",
        "        \n",
        "        try:\n",
        "            print(f\"Processing: '{unique_stem}'...\")\n",
        "            \n",
        "            # Generate and save audio\n",
        "            tts = gTTS(text=input_text, lang='en', slow=False)\n",
        "            tts.save(str(audio_path))\n",
        "            \n",
        "            # Save transcript\n",
        "            text_path.write_text(input_text, encoding=\"utf-8\")\n",
        "            \n",
        "            print(f\"\\t[✓] Transcript: {text_path.absolute()}\")\n",
        "            print(f\"\\t[✓] Audio:      {audio_path.absolute()}\\n\")\n",
        "            \n",
        "            return audio_path\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Failed to process {unique_stem}: {e}\")\n",
        "            return None\n",
        "    \n",
        "    \n",
        "    def batch_convert(self, input_texts: List[str], file_names: Optional[List[str]] = None) -> List[Path]:\n",
        "        \"\"\"Batch convert list of texts to audio files.\"\"\"\n",
        "        results = []\n",
        "        \n",
        "        if file_names:\n",
        "            assert len(input_texts) == len(file_names), \"Texts and filenames must have same length\"\n",
        "            for text, name in zip(input_texts, file_names):\n",
        "                result = self.convert(text, name)\n",
        "                if result:\n",
        "                    results.append(result)\n",
        "        else:\n",
        "            for text in input_texts:\n",
        "                result = self.convert(text)\n",
        "                if result:\n",
        "                    results.append(result)\n",
        "        \n",
        "        return results\n",
        "\n",
        "\n",
        "print(\"✓ TextToAudioPipeline class loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Audio Permutation Pipeline\n",
        "Apply various audio transformations: pitch shifting, speed changes, and reverb."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ AudioPermutationPipeline class loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "import librosa\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "from scipy.signal import fftconvolve\n",
        "from pydub import AudioSegment\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from typing import Optional\n",
        "\n",
        "\n",
        "class AudioPermutationPipeline:\n",
        "    \"\"\"Pipeline for applying audio transformations and effects.\"\"\"\n",
        "    \n",
        "    def __init__(self, output_dir: str = \"./outputs/\"):\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self._init_output_dir()\n",
        "    \n",
        "\n",
        "    def _init_output_dir(self):\n",
        "        \"\"\"Ensures the output directory exists.\"\"\"\n",
        "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "\n",
        "    @staticmethod\n",
        "    def shift_pitch(data, sr, n_steps=0):\n",
        "        \"\"\"\n",
        "        Shifts pitch (without changing duration).\n",
        "        - positive 'n_steps' increases pitch\n",
        "        - negative 'n_steps' decreases pitch \n",
        "        \"\"\"\n",
        "        return librosa.effects.pitch_shift(y=data, sr=sr, n_steps=n_steps)\n",
        "    \n",
        "\n",
        "    @staticmethod\n",
        "    def stretch_time(data, rate=1.0):\n",
        "        \"\"\"\n",
        "        Changes speed (without changing pitch).\n",
        "        - 'rate' > 1.0 increases speed\n",
        "        - 'rate' < 1.0 decreases speed\n",
        "        \"\"\"\n",
        "        return librosa.effects.time_stretch(y=data, rate=rate)\n",
        "    \n",
        "\n",
        "    @staticmethod\n",
        "    def apply_reverb(data, sr, room_size=0.5, wet_dry=0.3):\n",
        "        \"\"\"\n",
        "        Adds reverb effect to audio.\n",
        "        - 'room_size' controls the reverb length (0.0 to 1.0)\n",
        "        - 'wet_dry' mixes between original and reverb (0.0 = dry, 1.0 = wet)\n",
        "        \"\"\"\n",
        "        reverb_duration = room_size * 2.0\n",
        "        ir_length = int(reverb_duration * sr)\n",
        "        \n",
        "        t = np.linspace(0, reverb_duration, ir_length)\n",
        "        decay = np.exp(-3.0 * t / reverb_duration)\n",
        "        impulse = decay * np.random.randn(ir_length) * 0.1\n",
        "        \n",
        "        reverb_signal = fftconvolve(data, impulse, mode='same')\n",
        "        output = (1 - wet_dry) * data + wet_dry * reverb_signal\n",
        "        output = output / np.max(np.abs(output))\n",
        "        \n",
        "        return output\n",
        "    \n",
        "\n",
        "    @staticmethod\n",
        "    def save_as_mp3(data, sr, output_path):\n",
        "        \"\"\"Save audio data as MP3 file.\"\"\"\n",
        "        temp_wav = str(output_path).replace('.mp3', '_temp.wav')\n",
        "        sf.write(temp_wav, data, sr)\n",
        "        \n",
        "        audio = AudioSegment.from_wav(temp_wav)\n",
        "        audio.export(output_path, format='mp3', bitrate='192k')\n",
        "        \n",
        "        os.remove(temp_wav)\n",
        "    \n",
        "    \n",
        "    def process(self,\n",
        "                input_path: str,\n",
        "                pitch_increase: Optional[float] = None,\n",
        "                pitch_decrease: Optional[float] = None,\n",
        "                speed_increase: Optional[float] = None,\n",
        "                speed_decrease: Optional[float] = None,\n",
        "                reverb_room_size: Optional[float] = None):\n",
        "        \"\"\"\n",
        "        Process audio file with various transformations.\n",
        "        \n",
        "        Args:\n",
        "            input_path: path to input audio file\n",
        "            pitch_increase: positive number of semitones to increase pitch\n",
        "            pitch_decrease: negative number of semitones to decrease pitch\n",
        "            speed_increase: speed factor > 1.0 to increase speed\n",
        "            speed_decrease: speed factor < 1.0 to decrease speed\n",
        "            reverb_room_size: reverb room size (0.0 to 1.0)\n",
        "        \"\"\"\n",
        "        if not os.path.exists(input_path):\n",
        "            print(f\"Error: File '{input_path}' not found.\")\n",
        "            return\n",
        "        \n",
        "        # Validate inputs\n",
        "        assert pitch_increase is None or pitch_increase > 0, \"pitch_increase must be positive\"\n",
        "        assert pitch_decrease is None or pitch_decrease < 0, \"pitch_decrease must be negative\"\n",
        "        assert speed_increase is None or speed_increase > 1.0, \"speed_increase must be > 1.0\"\n",
        "        assert speed_decrease is None or (0 < speed_decrease < 1.0), \"speed_decrease must be between 0 and 1\"\n",
        "        assert reverb_room_size is None or (0 < reverb_room_size <= 1.0), \"reverb_room_size must be between 0 and 1\"\n",
        "        \n",
        "        # Create output subdirectory\n",
        "        base_name = Path(input_path).stem\n",
        "        output_subdir = self.output_dir / base_name\n",
        "        output_subdir.mkdir(parents=True, exist_ok=True)\n",
        "        \n",
        "        # Copy input file\n",
        "        print(f\"Copying input file to output directory...\")\n",
        "        original_copy = output_subdir / Path(input_path).name\n",
        "        shutil.copy2(input_path, original_copy)\n",
        "        print(f\"\\tCopied to: {original_copy}\\n\")\n",
        "        \n",
        "        # Load audio\n",
        "        print(f\"Loading audio file ('{input_path}')...\")\n",
        "        data, sr = librosa.load(input_path, sr=None)\n",
        "        \n",
        "        # Apply transformations\n",
        "        if pitch_increase:\n",
        "            print(f\"\\tGenerating pitch increase by {pitch_increase} semitones...\")\n",
        "            pitch_up = self.shift_pitch(data, sr, n_steps=pitch_increase)\n",
        "            output_path = output_subdir / f\"{base_name}_pitch_up.mp3\"\n",
        "            self.save_as_mp3(pitch_up, sr, output_path)\n",
        "            print(f\"\\t\\tSaved: {output_path}\\n\")\n",
        "        \n",
        "        if pitch_decrease:\n",
        "            print(f\"\\tGenerating pitch decrease by {pitch_decrease} semitones...\")\n",
        "            pitch_down = self.shift_pitch(data, sr, n_steps=pitch_decrease)\n",
        "            output_path = output_subdir / f\"{base_name}_pitch_down.mp3\"\n",
        "            self.save_as_mp3(pitch_down, sr, output_path)\n",
        "            print(f\"\\t\\tSaved: {output_path}\\n\")\n",
        "        \n",
        "        if speed_increase:\n",
        "            print(f\"\\tGenerating increased speed by factor of {speed_increase}...\")\n",
        "            speed_up = self.stretch_time(data, rate=speed_increase)\n",
        "            output_path = output_subdir / f\"{base_name}_speed_up.mp3\"\n",
        "            self.save_as_mp3(speed_up, sr, output_path)\n",
        "            print(f\"\\t\\tSaved: {output_path}\\n\")\n",
        "        \n",
        "        if speed_decrease:\n",
        "            print(f\"\\tGenerating decreased speed by factor of {speed_decrease}...\")\n",
        "            speed_down = self.stretch_time(data, rate=speed_decrease)\n",
        "            output_path = output_subdir / f\"{base_name}_speed_down.mp3\"\n",
        "            self.save_as_mp3(speed_down, sr, output_path)\n",
        "            print(f\"\\t\\tSaved: {output_path}\\n\")\n",
        "        \n",
        "        if reverb_room_size:\n",
        "            print(f\"\\tGenerating reverb (room size: {reverb_room_size})...\")\n",
        "            reverb = self.apply_reverb(data, sr, room_size=reverb_room_size)\n",
        "            output_path = output_subdir / f\"{base_name}_reverb.mp3\"\n",
        "            self.save_as_mp3(reverb, sr, output_path)\n",
        "            print(f\"\\t\\tSaved: {output_path}\\n\")\n",
        "        \n",
        "        print(f\"Done! All files saved to: {output_subdir}\\n\")\n",
        "\n",
        "\n",
        "print(\"✓ AudioPermutationPipeline class loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pipelines initialized!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Initialize pipelines\n",
        "text_pipeline = TextToAudioPipeline(output_dir=\"./outputs/\")\n",
        "audio_pipeline = AudioPermutationPipeline(output_dir=\"./outputs/\")\n",
        "\n",
        "print(\"Pipelines initialized!\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pipeline 1: Single Text-to-Audio Conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing: 'sample_output'...\n",
            "\t[✓] Transcript: /Users/saikrishna/Desktop/eccv_audio/eccv_audio/outputs/sample_output.txt\n",
            "\t[✓] Audio:      /Users/saikrishna/Desktop/eccv_audio/eccv_audio/outputs/sample_output.mp3\n",
            "\n",
            "Generated audio file: outputs/sample_output.mp3\n"
          ]
        }
      ],
      "source": [
        "# Single conversion\n",
        "sample_text = \"\"\"Hello, World! This is an audio file. Now I will read some random text.\n",
        "Paragraphs are the building blocks of papers. Many students define \n",
        "paragraphs in terms of length: a paragraph is a group of at least five \n",
        "sentences, a paragraph is half a page long, etc. In reality, though, the \n",
        "unity and coherence of ideas among sentences is what constitutes a paragraph.\"\"\"\n",
        "\n",
        "audio_file = text_pipeline.convert(sample_text, \"sample_output\")\n",
        "print(f\"Generated audio file: {audio_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pipeline 1: Batch Text-to-Audio Conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing: 'message_1'...\n",
            "\t[✓] Transcript: /Users/saikrishna/Desktop/eccv_audio/eccv_audio/outputs/message_1.txt\n",
            "\t[✓] Audio:      /Users/saikrishna/Desktop/eccv_audio/eccv_audio/outputs/message_1.mp3\n",
            "\n",
            "Processing: 'message_2'...\n",
            "\t[✓] Transcript: /Users/saikrishna/Desktop/eccv_audio/eccv_audio/outputs/message_2.txt\n",
            "\t[✓] Audio:      /Users/saikrishna/Desktop/eccv_audio/eccv_audio/outputs/message_2.mp3\n",
            "\n",
            "Processing: 'message_3'...\n",
            "\t[✓] Transcript: /Users/saikrishna/Desktop/eccv_audio/eccv_audio/outputs/message_3.txt\n",
            "\t[✓] Audio:      /Users/saikrishna/Desktop/eccv_audio/eccv_audio/outputs/message_3.mp3\n",
            "\n",
            "\n",
            "Generated 3 audio files.\n"
          ]
        }
      ],
      "source": [
        "# Batch conversion\n",
        "texts = [\n",
        "    \"This is the first audio message.\",\n",
        "    \"This is the second audio message.\",\n",
        "    \"This is the third audio message.\"\n",
        "]\n",
        "\n",
        "filenames = [\"message_1\", \"message_2\", \"message_3\"]\n",
        "\n",
        "audio_files = text_pipeline.batch_convert(texts, filenames)\n",
        "print(f\"\\nGenerated {len(audio_files)} audio files.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pipeline 2: Audio Permutations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copying input file to output directory...\n",
            "\tCopied to: outputs/sample_output/sample_output.mp3\n",
            "\n",
            "Loading audio file ('./outputs/sample_output.mp3')...\n",
            "\tGenerating pitch increase by 4 semitones...\n",
            "\t\tSaved: outputs/sample_output/sample_output_pitch_up.mp3\n",
            "\n",
            "\tGenerating pitch decrease by -4 semitones...\n",
            "\t\tSaved: outputs/sample_output/sample_output_pitch_down.mp3\n",
            "\n",
            "\tGenerating increased speed by factor of 1.5...\n",
            "\t\tSaved: outputs/sample_output/sample_output_speed_up.mp3\n",
            "\n",
            "\tGenerating decreased speed by factor of 0.5...\n",
            "\t\tSaved: outputs/sample_output/sample_output_speed_down.mp3\n",
            "\n",
            "\tGenerating reverb (room size: 0.5)...\n",
            "\t\tSaved: outputs/sample_output/sample_output_reverb.mp3\n",
            "\n",
            "Done! All files saved to: outputs/sample_output\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Apply transformations to an existing audio file\n",
        "audio_pipeline.process(\n",
        "    \"./outputs/sample_output.mp3\",  # Use the file we just created\n",
        "    pitch_increase=4,\n",
        "    pitch_decrease=-4,\n",
        "    speed_increase=1.5,\n",
        "    speed_decrease=0.5,\n",
        "    reverb_room_size=0.5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Linking Pipelines: Generate Text-to-Audio, then Generate Audio Permutations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "STEP 1: Converting text to audio...\n",
            "Processing: 'complete_pipeline_test'...\n",
            "\t[✓] Transcript: /Users/saikrishna/Desktop/eccv_audio/eccv_audio/outputs/complete_pipeline_test.txt\n",
            "\t[✓] Audio:      /Users/saikrishna/Desktop/eccv_audio/eccv_audio/outputs/complete_pipeline_test.mp3\n",
            "\n",
            "\n",
            "STEP 2: Applying audio effects...\n",
            "Copying input file to output directory...\n",
            "\tCopied to: outputs/complete_pipeline_test/complete_pipeline_test.mp3\n",
            "\n",
            "Loading audio file ('outputs/complete_pipeline_test.mp3')...\n",
            "\tGenerating pitch increase by 5 semitones...\n",
            "\t\tSaved: outputs/complete_pipeline_test/complete_pipeline_test_pitch_up.mp3\n",
            "\n",
            "\tGenerating pitch decrease by -5 semitones...\n",
            "\t\tSaved: outputs/complete_pipeline_test/complete_pipeline_test_pitch_down.mp3\n",
            "\n",
            "\tGenerating increased speed by factor of 2.0...\n",
            "\t\tSaved: outputs/complete_pipeline_test/complete_pipeline_test_speed_up.mp3\n",
            "\n",
            "\tGenerating reverb (room size: 0.7)...\n",
            "\t\tSaved: outputs/complete_pipeline_test/complete_pipeline_test_reverb.mp3\n",
            "\n",
            "Done! All files saved to: outputs/complete_pipeline_test\n",
            "\n",
            "\n",
            "✓ Complete pipeline finished successfully!\n"
          ]
        }
      ],
      "source": [
        "# Chain both pipelines together\n",
        "print(\"STEP 1: Converting text to audio...\")\n",
        "\n",
        "text = \"The quick brown fox jumps over the lazy dog. This is a test of the audio processing pipeline.\"\n",
        "audio_path = text_pipeline.convert(text, \"complete_pipeline_test\")\n",
        "\n",
        "print(\"\\nSTEP 2: Applying audio effects...\")\n",
        "\n",
        "if audio_path:\n",
        "    audio_pipeline.process(\n",
        "        str(audio_path),\n",
        "        pitch_increase=5,\n",
        "        pitch_decrease=-5,\n",
        "        speed_increase=2.0,\n",
        "        reverb_room_size=0.7\n",
        "    )\n",
        "    print(\"\\n✓ Complete pipeline finished successfully!\")\n",
        "else:\n",
        "    print(\"Failed to generate audio file.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
