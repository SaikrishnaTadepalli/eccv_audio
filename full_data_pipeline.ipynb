{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVb775umCbtg"
      },
      "source": [
        "# Complete Data Pipeline\n",
        "\n",
        "This notebook demonstrates a complete end-to-end pipeline:\n",
        "1. **HFDataIndexer**: Lazy loading of Hugging Face datasets\n",
        "2. **TextToAudioPipeline**: Convert text to MP3 audio files\n",
        "3. **AudioPermutationPipeline**: Apply audio transformations (pitch, speed, reverb)\n",
        "4. **End-to-End Examples**: Chain all pipelines together"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn5aEvLWCbth"
      },
      "source": [
        "## Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "X5_O42-BCbth"
      },
      "outputs": [],
      "source": [
        "%pip install datasets gtts librosa soundfile pydub scipy numpy -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXAT_0gRCbth"
      },
      "source": [
        "## Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "4L-wdLicCbth"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "from scipy.signal import fftconvolve\n",
        "from pydub import AudioSegment\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from typing import List, Optional\n",
        "from datasets import load_dataset\n",
        "from gtts import gTTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeMGIkMFCbth"
      },
      "source": [
        "---\n",
        "## 1. HFDataIndexer Class\n",
        "Enables lazy indexing over Hugging Face datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "jgsXYLWZCbth",
        "outputId": "5f315a18-485c-45eb-d998-d07bc54168a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ HFDataIndexer class loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "class HFDataIndexer:\n",
        "    \"\"\"\n",
        "    Lazy indexer for Hugging Face datasets.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, path, name=None, split='train'):\n",
        "        self.path = path\n",
        "        self.split = split\n",
        "        try:\n",
        "            self.dataset = load_dataset(path, name, split=split, streaming=True)\n",
        "\n",
        "            # Peek at one row to get column names without loading the rest\n",
        "            first_row = next(iter(self.dataset))\n",
        "            self.columns = list(first_row.keys())\n",
        "\n",
        "            print(f\"--- Connected to {path} ({split}) ---\")\n",
        "            print(f\"Columns available: {self.columns}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Connection Error: {e}\")\n",
        "            sys.exit(1)\n",
        "\n",
        "    def get_rows(self, start=0, count=1, target_columns=None):\n",
        "        \"\"\"\n",
        "        Stream a specific range of rows. Returns a generator to\n",
        "        minimize memory footprint.\n",
        "        \"\"\"\n",
        "        cols = target_columns if target_columns else self.columns\n",
        "\n",
        "        # \"lazy\" indexing in streaming mode uses skip() and take()\n",
        "        subset = self.dataset.skip(start).take(count)\n",
        "\n",
        "        for row in subset:\n",
        "            yield { col: row.get(col) for col in cols }\n",
        "\n",
        "    def get_cell(self, row_idx, col_name):\n",
        "        \"\"\"\n",
        "        Grab a single specific 'cell'.\n",
        "        \"\"\"\n",
        "        if col_name not in self.columns:\n",
        "            return None\n",
        "\n",
        "        # skip to row_idx, take 1 row, get the first item\n",
        "        row = next(iter(self.dataset.skip(row_idx).take(1)), None)\n",
        "\n",
        "        return row.get(col_name) if row else None\n",
        "\n",
        "print(\"✓ HFDataIndexer class loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSwEckxSCbti"
      },
      "source": [
        "---\n",
        "## 2. TextToAudioPipeline Class\n",
        "Converts text into MP3 audio files using Google Text-to-Speech"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "GgoalP-dCbti",
        "outputId": "34f2cf4e-b3d2-4102-fcb5-455747bac38b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ TextToAudioPipeline class loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "class TextToAudioPipeline:\n",
        "    \"\"\"Pipeline for converting text to MP3 audio files.\"\"\"\n",
        "\n",
        "    def __init__(self, output_dir: str = \"./outputs/\"):\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self._init_output_dir()\n",
        "\n",
        "    def _init_output_dir(self):\n",
        "        \"\"\"Ensures the output directory exists.\"\"\"\n",
        "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    def _get_unique_filename(self, base_name: str) -> str:\n",
        "        \"\"\"\n",
        "        Checks for file existence and returns a unique filename string.\n",
        "        Example: 'test' -> 'test_v1' if 'test.mp3' exists.\n",
        "        \"\"\"\n",
        "        stem = Path(base_name).stem\n",
        "        candidate_stem = stem\n",
        "        counter = 1\n",
        "\n",
        "        while (self.output_dir / f\"{candidate_stem}.mp3\").exists() or \\\n",
        "              (self.output_dir / f\"{candidate_stem}.txt\").exists():\n",
        "            candidate_stem = f\"{stem}_v{counter}\"\n",
        "            counter += 1\n",
        "\n",
        "        return candidate_stem\n",
        "\n",
        "    def convert(self, input_text: str, output_filename: str = \"file_save\") -> Optional[Path]:\n",
        "        \"\"\"Converts text to an MP3 and saves a transcript copy.\"\"\"\n",
        "        if not input_text.strip():\n",
        "            print(\"Error: Input text is empty.\")\n",
        "            return None\n",
        "\n",
        "        unique_stem = self._get_unique_filename(output_filename)\n",
        "        audio_path = self.output_dir / f\"{unique_stem}.mp3\"\n",
        "        text_path = self.output_dir / f\"{unique_stem}.txt\"\n",
        "\n",
        "        try:\n",
        "            print(f\"Processing: '{unique_stem}'...\")\n",
        "\n",
        "            # Generate and save audio\n",
        "            tts = gTTS(text=input_text, lang='en', slow=False)\n",
        "            tts.save(str(audio_path))\n",
        "\n",
        "            # Save transcript\n",
        "            text_path.write_text(input_text, encoding=\"utf-8\")\n",
        "\n",
        "            print(f\"\\t[✓] Transcript: {text_path.absolute()}\")\n",
        "            print(f\"\\t[✓] Audio:      {audio_path.absolute()}\\n\")\n",
        "\n",
        "            return audio_path\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to process {unique_stem}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def batch_convert(self, input_texts: List[str], file_names: Optional[List[str]] = None) -> List[Path]:\n",
        "        \"\"\"Batch convert list of texts to audio files.\"\"\"\n",
        "        results = []\n",
        "\n",
        "        if file_names:\n",
        "            assert len(input_texts) == len(file_names), \"Texts and filenames must have same length\"\n",
        "            for text, name in zip(input_texts, file_names):\n",
        "                result = self.convert(text, name)\n",
        "                if result:\n",
        "                    results.append(result)\n",
        "        else:\n",
        "            for text in input_texts:\n",
        "                result = self.convert(text)\n",
        "                if result:\n",
        "                    results.append(result)\n",
        "\n",
        "        return results\n",
        "\n",
        "print(\"✓ TextToAudioPipeline class loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MwzxOnWCbti"
      },
      "source": [
        "---\n",
        "## 3. AudioPermutationPipeline Class\n",
        "Apply various audio transformations: pitch shifting, speed changes, and reverb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "4SBDGU3xCbti",
        "outputId": "20229e77-bf25-40bb-cb2c-6e856774596e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ AudioPermutationPipeline class loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "class AudioPermutationPipeline:\n",
        "    \"\"\"Pipeline for applying audio transformations and effects.\"\"\"\n",
        "\n",
        "    def __init__(self, output_dir: str = \"./outputs/\"):\n",
        "        self.output_dir = Path(output_dir)\n",
        "        self._init_output_dir()\n",
        "\n",
        "\n",
        "    def _init_output_dir(self):\n",
        "        \"\"\"Ensures the output directory exists.\"\"\"\n",
        "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def _shift_pitch(data, sr, n_steps=0):\n",
        "        \"\"\"\n",
        "        Shifts pitch (without changing duration).\n",
        "\n",
        "        Args:\n",
        "            - positive 'n_steps' increases pitch\n",
        "            - negative 'n_steps' decreases pitch\n",
        "        \"\"\"\n",
        "        return librosa.effects.pitch_shift(y=data, sr=sr, n_steps=n_steps)\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def _stretch_time(data, rate=1.0):\n",
        "        \"\"\"\n",
        "        Changes speed (without changing pitch).\n",
        "\n",
        "        Args:\n",
        "            - 'rate' > 1.0 increases speed\n",
        "            - 'rate' < 1.0 decreases speed\n",
        "        \"\"\"\n",
        "        return librosa.effects.time_stretch(y=data, rate=rate)\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def _apply_reverb(data, sr, room_size=0.5, wet_dry=0.3):\n",
        "        \"\"\"\n",
        "        Adds reverb effect to audio.\n",
        "\n",
        "        Args:\n",
        "            - 'room_size' controls the reverb length (0.0 to 1.0)\n",
        "            - 'wet_dry' mixes between original and reverb (0.0 = dry, 1.0 = wet)\n",
        "        \"\"\"\n",
        "        reverb_duration = room_size * 2.0\n",
        "        ir_length = int(reverb_duration * sr)\n",
        "\n",
        "        t = np.linspace(0, reverb_duration, ir_length)\n",
        "        decay = np.exp(-3.0 * t / reverb_duration)\n",
        "        impulse = decay * np.random.randn(ir_length) * 0.1\n",
        "\n",
        "        reverb_signal = fftconvolve(data, impulse, mode='same')\n",
        "        output = (1 - wet_dry) * data + wet_dry * reverb_signal\n",
        "        output = output / np.max(np.abs(output))\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def _overlay_audio(data, sr, overlay_path, volume_ratio=1.0):\n",
        "        \"\"\"\n",
        "        Overlays a secondary audio file onto the original audio.\n",
        "\n",
        "        Args:\n",
        "            - data: original audio data (numpy array)\n",
        "            - sr: sample rate of original audio\n",
        "            - overlay_path: path to the secondary audio file to overlay\n",
        "            - volume_ratio: volume of overlay relative to original (1.0 = equal volume, 0.5 = half volume)\n",
        "\n",
        "        Returns:\n",
        "            numpy array with overlaid audio\n",
        "        \"\"\"\n",
        "        # Load the overlay audio file\n",
        "        overlay_data, overlay_sr = librosa.load(overlay_path, sr=sr)\n",
        "\n",
        "        # Get lengths\n",
        "        original_length = len(data)\n",
        "        overlay_length = len(overlay_data)\n",
        "\n",
        "        # Handle length differences\n",
        "        if overlay_length < original_length:\n",
        "            # Loop the overlay to match original length\n",
        "            num_repeats = int(np.ceil(original_length / overlay_length))\n",
        "            overlay_data = np.tile(overlay_data, num_repeats)[:original_length]\n",
        "        elif overlay_length > original_length:\n",
        "            # Trim the overlay to match original length\n",
        "            overlay_data = overlay_data[:original_length]\n",
        "\n",
        "        # Apply volume ratio to overlay\n",
        "        overlay_data = overlay_data * volume_ratio\n",
        "\n",
        "        # Mix the two audio signals\n",
        "        mixed = data + overlay_data\n",
        "\n",
        "        # Normalize to prevent clipping\n",
        "        max_val = np.max(np.abs(mixed))\n",
        "        if max_val > 1.0: mixed = mixed / max_val\n",
        "\n",
        "        return mixed\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def _save_as_mp3(data, sr, output_path):\n",
        "        \"\"\"Save audio data as MP3 file.\"\"\"\n",
        "        temp_wav = str(output_path).replace('.mp3', '_temp.wav')\n",
        "        sf.write(temp_wav, data, sr)\n",
        "\n",
        "        audio = AudioSegment.from_wav(temp_wav)\n",
        "        audio.export(output_path, format='mp3', bitrate='192k')\n",
        "\n",
        "        os.remove(temp_wav)\n",
        "\n",
        "\n",
        "    def process(self,\n",
        "                input_path: str,\n",
        "                pitch_increase: Optional[float] = None,\n",
        "                pitch_decrease: Optional[float] = None,\n",
        "                speed_increase: Optional[float] = None,\n",
        "                speed_decrease: Optional[float] = None,\n",
        "                reverb_room_size: Optional[float] = None):\n",
        "        \"\"\"\n",
        "        Process audio file with various transformations.\n",
        "\n",
        "        Args:\n",
        "            - input_path: path to input audio file\n",
        "            - pitch_increase: positive number of semitones to increase pitch\n",
        "            - pitch_decrease: negative number of semitones to decrease pitch\n",
        "            - speed_increase: speed factor > 1.0 to increase speed\n",
        "            - speed_decrease: speed factor < 1.0 to decrease speed\n",
        "            - reverb_room_size: reverb room size (0.0 to 1.0)\n",
        "        \"\"\"\n",
        "        if not os.path.exists(input_path):\n",
        "            print(f\"Error: File '{input_path}' not found.\")\n",
        "            return\n",
        "\n",
        "        # Validate inputs\n",
        "        assert pitch_increase is None or pitch_increase > 0, \"pitch_increase must be positive\"\n",
        "        assert pitch_decrease is None or pitch_decrease < 0, \"pitch_decrease must be negative\"\n",
        "        assert speed_increase is None or speed_increase > 1.0, \"speed_increase must be > 1.0\"\n",
        "        assert speed_decrease is None or (0 < speed_decrease < 1.0), \"speed_decrease must be between 0 and 1\"\n",
        "        assert reverb_room_size is None or (0 < reverb_room_size <= 1.0), \"reverb_room_size must be between 0 and 1\"\n",
        "\n",
        "        # Create output subdirectory\n",
        "        base_name = Path(input_path).stem\n",
        "        output_subdir = self.output_dir / base_name\n",
        "        output_subdir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Copy input file\n",
        "        print(f\"Copying input file to output directory...\")\n",
        "        original_copy = output_subdir / Path(input_path).name\n",
        "        shutil.copy2(input_path, original_copy)\n",
        "        print(f\"\\tCopied to: {original_copy}\\n\")\n",
        "\n",
        "        # Load audio\n",
        "        print(f\"Loading audio file ('{input_path}')...\")\n",
        "        data, sr = librosa.load(input_path, sr=None)\n",
        "\n",
        "        # Apply transformations\n",
        "        if pitch_increase:\n",
        "            print(f\"\\tGenerating pitch increase by {pitch_increase} semitones...\")\n",
        "            pitch_up = self._shift_pitch(data, sr, n_steps=pitch_increase)\n",
        "            output_path = output_subdir / f\"{base_name}_pitch_up.mp3\"\n",
        "            self._save_as_mp3(pitch_up, sr, output_path)\n",
        "            print(f\"\\t\\tSaved: {output_path}\\n\")\n",
        "\n",
        "        if pitch_decrease:\n",
        "            print(f\"\\tGenerating pitch decrease by {pitch_decrease} semitones...\")\n",
        "            pitch_down = self._shift_pitch(data, sr, n_steps=pitch_decrease)\n",
        "            output_path = output_subdir / f\"{base_name}_pitch_down.mp3\"\n",
        "            self._save_as_mp3(pitch_down, sr, output_path)\n",
        "            print(f\"\\t\\tSaved: {output_path}\\n\")\n",
        "\n",
        "        if speed_increase:\n",
        "            print(f\"\\tGenerating increased speed by factor of {speed_increase}...\")\n",
        "            speed_up = self._stretch_time(data, rate=speed_increase)\n",
        "            output_path = output_subdir / f\"{base_name}_speed_up.mp3\"\n",
        "            self._save_as_mp3(speed_up, sr, output_path)\n",
        "            print(f\"\\t\\tSaved: {output_path}\\n\")\n",
        "\n",
        "        if speed_decrease:\n",
        "            print(f\"\\tGenerating decreased speed by factor of {speed_decrease}...\")\n",
        "            speed_down = self._stretch_time(data, rate=speed_decrease)\n",
        "            output_path = output_subdir / f\"{base_name}_speed_down.mp3\"\n",
        "            self._save_as_mp3(speed_down, sr, output_path)\n",
        "            print(f\"\\t\\tSaved: {output_path}\\n\")\n",
        "\n",
        "        if reverb_room_size:\n",
        "            print(f\"\\tGenerating reverb (room size: {reverb_room_size})...\")\n",
        "            reverb = self._apply_reverb(data, sr, room_size=reverb_room_size)\n",
        "            output_path = output_subdir / f\"{base_name}_reverb.mp3\"\n",
        "            self._save_as_mp3(reverb, sr, output_path)\n",
        "            print(f\"\\t\\tSaved: {output_path}\\n\")\n",
        "\n",
        "        print(f\"Done! All files saved to: {output_subdir}\\n\")\n",
        "\n",
        "\n",
        "    def apply_overlay(self,\n",
        "                      original_audio_path: str,\n",
        "                      overlay_audio_path: str,\n",
        "                      overlay_volume: float):\n",
        "        \"\"\"\n",
        "        Apply audio overlay effect to an audio file.\n",
        "\n",
        "        Args:\n",
        "            - original_audio_path: path to the original audio file\n",
        "            - overlay_audio_path: path to the overlay audio file\n",
        "            - overlay_volume: volume of overlay relative to original (1.0 = equal, 0.5 = half)\n",
        "        \"\"\"\n",
        "        # Check if original file exists\n",
        "        if not os.path.exists(original_audio_path):\n",
        "            print(f\"Error: File '{original_audio_path}' not found.\")\n",
        "            return\n",
        "\n",
        "        # Check if overlay file exists\n",
        "        if not os.path.exists(overlay_audio_path):\n",
        "            print(f\"Error: Overlay file '{overlay_audio_path}' not found.\")\n",
        "            return\n",
        "\n",
        "        # Create output subdirectory\n",
        "        base_name = Path(original_audio_path).stem\n",
        "        output_subdir = self.output_dir / base_name\n",
        "        output_subdir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Copy input file\n",
        "        print(f\"Copying input file to output directory...\")\n",
        "        original_copy = output_subdir / Path(original_audio_path).name\n",
        "        shutil.copy2(original_audio_path, original_copy)\n",
        "        print(f\"\\tCopied to: {original_copy}\\n\")\n",
        "\n",
        "        # Load audio\n",
        "        print(f\"Loading audio file ('{original_audio_path}')...\")\n",
        "        data, sr = librosa.load(original_audio_path, sr=None)\n",
        "\n",
        "        # Apply overlay\n",
        "        print(f\"\\tApplying overlay from '{overlay_audio_path}' at relative volume {overlay_volume}...\")\n",
        "        overlaid = self._overlay_audio(data, sr, overlay_audio_path, volume_ratio=overlay_volume)\n",
        "\n",
        "        # Save output\n",
        "        overlay_base_name = Path(overlay_audio_path).stem\n",
        "        output_path = output_subdir / f\"{base_name}_overlay_{overlay_base_name}.mp3\"\n",
        "        self._save_as_mp3(overlaid, sr, output_path)\n",
        "        print(f\"\\t\\tSaved: {output_path}\\n\")\n",
        "\n",
        "        print(f\"Done! File saved to: {output_subdir}\\n\")\n",
        "\n",
        "\n",
        "print(\"✓ AudioPermutationPipeline class loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSt3r23NCbti"
      },
      "source": [
        "---\n",
        "# Usage Examples\n",
        "\n",
        "## Initialize All Pipelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "4KPLx2hJCbti",
        "outputId": "ee926f86-e34b-4beb-aed4-b590b328cc5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Connected to TIGER-Lab/MMLU-Pro (validation) ---\n",
            "Columns available: ['question_id', 'question', 'options', 'answer', 'answer_index', 'cot_content', 'category', 'src']\n",
            "\n",
            "All pipelines initialized!\n"
          ]
        }
      ],
      "source": [
        "# Initialize all pipelines\n",
        "indexer = HFDataIndexer(\"TIGER-Lab/MMLU-Pro\", split=\"validation\")\n",
        "text_pipeline = TextToAudioPipeline(output_dir=\"./outputs/\")\n",
        "audio_pipeline = AudioPermutationPipeline(output_dir=\"./outputs/\")\n",
        "\n",
        "print(\"\\nAll pipelines initialized!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHJxwc1VCbti"
      },
      "source": [
        "---\n",
        "## Example 1: HFDataIndexer Single 'Cell' Indexing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "2koWahK3Cbti",
        "outputId": "2df104e6-d031-4d25-d60b-db5abfcf3650",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cell Index [5, 'question']:\n",
            "Which of the following is the body cavity that contains the pituitary gland?...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Grab a specific cell (Row 5, Column 'question')\n",
        "question_5 = indexer.get_cell(5, \"question\")\n",
        "print(f\"Cell Index [5, 'question']:\\n{question_5[:100]}...\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBaJczEcCbti"
      },
      "source": [
        "---\n",
        "## Example 2: HFDataIndexer Data-Set Iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "fTJ6w5oDCbti",
        "outputId": "23c23083-d880-478e-bce4-dffc7307fd8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streaming Rows 10 - 13 ...\n",
            "\n",
            "\n",
            "Row 10:\n",
            "\n",
            "question:\n",
            "Say the pupil of your eye has a diameter of 5 mm and you have a telescope with an aperture of 50 cm. How much more light can the telescope gather than your eye?\n",
            "\n",
            "\n",
            "options:\n",
            "['1000 times more', '50 times more', '5000 times more', '500 times more', '10000 times more', '20000 times more', '2000 times more', '100 times more', '10 times more', 'N/A']\n",
            "\n",
            "\n",
            "answer:\n",
            "E\n",
            "\n",
            "\n",
            "-------------------------\n",
            "\n",
            "\n",
            "Row 11:\n",
            "\n",
            "question:\n",
            "Where do most short-period comets come from and how do we know?\n",
            "\n",
            "\n",
            "options:\n",
            "['The Kuiper belt; short period comets tend to be in the plane of the solar system just like the Kuiper belt.', 'The asteroid belt; short period comets tend to come from random directions indicating a spherical distribution of comets called the asteroid belt.', 'The asteroid belt; short period comets tend to be in the plane of the solar system just like the asteroid belt.', 'The Oort cloud; short period comets have orbital periods similar to asteroids like Vesta and are found in the plane of the solar system just like the Oort cloud.', 'The Oort Cloud; short period comets tend to come from random directions indicating a spherical distribution of comets called the Oort Cloud.', 'The Oort cloud; short period comets tend to be in the plane of the solar system just like the Oort cloud.', 'The asteroid belt; short period comets have orbital periods similar to asteroids like Vesta and are found in the plane of the solar system just like the asteroid belt.', 'N/A', 'N/A', 'N/A']\n",
            "\n",
            "\n",
            "answer:\n",
            "A\n",
            "\n",
            "\n",
            "-------------------------\n",
            "\n",
            "\n",
            "Row 12:\n",
            "\n",
            "question:\n",
            "A refracting telescope consists of two converging lenses separated by 100 cm. The eye-piece lens has a focal length of 20 cm. The angular magnification of the telescope is\n",
            "\n",
            "\n",
            "options:\n",
            "['10', '40', '6', '25', '15', '50', '30', '4', '5', '20']\n",
            "\n",
            "\n",
            "answer:\n",
            "H\n",
            "\n",
            "\n",
            "-------------------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Iterate over a range (Rows 10 to 13)\n",
        "print(\"Streaming Rows 10 - 13 ...\\n\\n\")\n",
        "\n",
        "fields = ['question', 'options', 'answer']\n",
        "data_stream = indexer.get_rows(start=10, count=3, target_columns=fields)\n",
        "\n",
        "for i, entry in enumerate(data_stream, start=10):\n",
        "    extracted_fields = [f\"{f}:\\n{entry.get(f, None)}\\n\\n\" for f in fields]\n",
        "    print(f\"Row {i}:\\n\\n\" + \"\\n\".join(extracted_fields) + \"\\n\" + \"-\" * 25 + \"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoeVqhBVCbtj"
      },
      "source": [
        "---\n",
        "## Example 3: Single Text-to-Audio Conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "x-dvtF6UCbtj",
        "outputId": "e3c2a0db-45b6-4f4d-87d3-506b7977561f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: 'sample_output'...\n",
            "\t[✓] Transcript: /content/outputs/sample_output.txt\n",
            "\t[✓] Audio:      /content/outputs/sample_output.mp3\n",
            "\n",
            "Generated audio file: outputs/sample_output.mp3\n"
          ]
        }
      ],
      "source": [
        "# Single conversion\n",
        "sample_text = \"\"\"Hello, World! This is an audio file. Now I will read some random text.\n",
        "Paragraphs are the building blocks of papers. Many students define\n",
        "paragraphs in terms of length: a paragraph is a group of at least five\n",
        "sentences, a paragraph is half a page long, etc. In reality, though, the\n",
        "unity and coherence of ideas among sentences is what constitutes a paragraph.\"\"\"\n",
        "\n",
        "audio_file = text_pipeline.convert(sample_text, \"sample_output\")\n",
        "print(f\"Generated audio file: {audio_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hukdj6D6Cbtj"
      },
      "source": [
        "---\n",
        "## Example 4: Batch Text-to-Audio Conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "NXSetdGOCbtj",
        "outputId": "7e74e10e-cfe9-44ad-e584-8fa30968fa9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: 'message_1'...\n",
            "\t[✓] Transcript: /content/outputs/message_1.txt\n",
            "\t[✓] Audio:      /content/outputs/message_1.mp3\n",
            "\n",
            "Processing: 'message_2'...\n",
            "\t[✓] Transcript: /content/outputs/message_2.txt\n",
            "\t[✓] Audio:      /content/outputs/message_2.mp3\n",
            "\n",
            "Processing: 'message_3'...\n",
            "\t[✓] Transcript: /content/outputs/message_3.txt\n",
            "\t[✓] Audio:      /content/outputs/message_3.mp3\n",
            "\n",
            "\n",
            "Generated 3 audio files.\n"
          ]
        }
      ],
      "source": [
        "# Batch conversion\n",
        "texts = [\n",
        "    \"This is the first audio message.\",\n",
        "    \"This is the second audio message.\",\n",
        "    \"This is the third audio message.\"\n",
        "]\n",
        "\n",
        "filenames = [\"message_1\", \"message_2\", \"message_3\"]\n",
        "\n",
        "audio_files = text_pipeline.batch_convert(texts, filenames)\n",
        "print(f\"\\nGenerated {len(audio_files)} audio files.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-YbSxrICbtj"
      },
      "source": [
        "---\n",
        "## Example 5: Audio Permutations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "CNgUQOglCbtj",
        "outputId": "f88051ed-e651-4730-ec8f-0cc2e03ef30c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying input file to output directory...\n",
            "\tCopied to: outputs/sample_output/sample_output.mp3\n",
            "\n",
            "Loading audio file ('./outputs/sample_output.mp3')...\n",
            "\tGenerating pitch increase by 4 semitones...\n",
            "\t\tSaved: outputs/sample_output/sample_output_pitch_up.mp3\n",
            "\n",
            "\tGenerating pitch decrease by -4 semitones...\n",
            "\t\tSaved: outputs/sample_output/sample_output_pitch_down.mp3\n",
            "\n",
            "\tGenerating increased speed by factor of 1.5...\n",
            "\t\tSaved: outputs/sample_output/sample_output_speed_up.mp3\n",
            "\n",
            "\tGenerating decreased speed by factor of 0.5...\n",
            "\t\tSaved: outputs/sample_output/sample_output_speed_down.mp3\n",
            "\n",
            "\tGenerating reverb (room size: 0.5)...\n",
            "\t\tSaved: outputs/sample_output/sample_output_reverb.mp3\n",
            "\n",
            "Done! All files saved to: outputs/sample_output\n",
            "\n",
            "Copying input file to output directory...\n",
            "\tCopied to: outputs/sample_output/sample_output.mp3\n",
            "\n",
            "Loading audio file ('./outputs/sample_output.mp3')...\n",
            "\tApplying overlay from './saved_effects/wind.mp3' at relative volume 0.75...\n",
            "\t\tSaved: outputs/sample_output/sample_output_overlay_wind.mp3\n",
            "\n",
            "Done! File saved to: outputs/sample_output\n",
            "\n",
            "Copying input file to output directory...\n",
            "\tCopied to: outputs/sample_output/sample_output.mp3\n",
            "\n",
            "Loading audio file ('./outputs/sample_output.mp3')...\n",
            "\tApplying overlay from './saved_effects/rain.mp3' at relative volume 1.25...\n",
            "\t\tSaved: outputs/sample_output/sample_output_overlay_rain.mp3\n",
            "\n",
            "Done! File saved to: outputs/sample_output\n",
            "\n",
            "Copying input file to output directory...\n",
            "\tCopied to: outputs/sample_output/sample_output.mp3\n",
            "\n",
            "Loading audio file ('./outputs/sample_output.mp3')...\n",
            "\tApplying overlay from './saved_effects/coffee_shop.mp3' at relative volume 1.4...\n",
            "\t\tSaved: outputs/sample_output/sample_output_overlay_coffee_shop.mp3\n",
            "\n",
            "Done! File saved to: outputs/sample_output\n",
            "\n",
            "Copying input file to output directory...\n",
            "\tCopied to: outputs/sample_output/sample_output.mp3\n",
            "\n",
            "Loading audio file ('./outputs/sample_output.mp3')...\n",
            "\tApplying overlay from './saved_effects/busy_street.mp3' at relative volume 0.6...\n",
            "\t\tSaved: outputs/sample_output/sample_output_overlay_busy_street.mp3\n",
            "\n",
            "Done! File saved to: outputs/sample_output\n",
            "\n",
            "Copying input file to output directory...\n",
            "\tCopied to: outputs/sample_output/sample_output.mp3\n",
            "\n",
            "Loading audio file ('./outputs/sample_output.mp3')...\n",
            "\tApplying overlay from './saved_effects/song1.mp3' at relative volume 0.35...\n",
            "\t\tSaved: outputs/sample_output/sample_output_overlay_song1.mp3\n",
            "\n",
            "Done! File saved to: outputs/sample_output\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Apply basic transformations to an existing audio file\n",
        "audio_pipeline.process(\n",
        "    \"./outputs/sample_output.mp3\",  # Use the file we just created\n",
        "    pitch_increase=4,\n",
        "    pitch_decrease=-4,\n",
        "    speed_increase=1.5,\n",
        "    speed_decrease=0.5,\n",
        "    reverb_room_size=0.5\n",
        ")\n",
        "\n",
        "# Adding background noise effects\n",
        "background_noise_effects = [\n",
        "    # https://www.youtube.com/watch?v=5jlUVr6gkos\n",
        "    (\"./saved_effects/wind.mp3\", 0.75),\n",
        "\n",
        "    # https://www.youtube.com/watch?v=C4pJ6Hi4MU4\n",
        "    (\"./saved_effects/rain.mp3\", 1.25),\n",
        "\n",
        "    # https://www.youtube.com/watch?v=wyzgbdI6x24\n",
        "    (\"./saved_effects/coffee_shop.mp3\", 1.4),\n",
        "\n",
        "    # https://www.youtube.com/watch?v=FeOrG8FrNko\n",
        "    (\"./saved_effects/busy_street.mp3\", 0.6),\n",
        "\n",
        "    # https://www.youtube.com/watch?v=cNWxqMx69WI\n",
        "    (\"./saved_effects/song1.mp3\", 0.35),\n",
        "]\n",
        "\n",
        "for background_audio_path, relative_volume in background_noise_effects:\n",
        "    audio_pipeline.apply_overlay(\n",
        "        \"./outputs/sample_output.mp3\",\n",
        "        background_audio_path,\n",
        "        relative_volume\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy4bLATaCbtj"
      },
      "source": [
        "---\n",
        "## Example 6: Linked Audio Pipelines\n",
        "**Text → Audio Generation → Permutations Permutation Generation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "kym71QdPCbtj",
        "outputId": "23b9f842-9f20-450f-c09b-f59301205f61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 1: Converting text to audio...\n",
            "Processing: 'complete_pipeline_test'...\n",
            "\t[✓] Transcript: /content/outputs/complete_pipeline_test.txt\n",
            "\t[✓] Audio:      /content/outputs/complete_pipeline_test.mp3\n",
            "\n",
            "\n",
            "STEP 2: Applying audio effects...\n",
            "Copying input file to output directory...\n",
            "\tCopied to: outputs/complete_pipeline_test/complete_pipeline_test.mp3\n",
            "\n",
            "Loading audio file ('outputs/complete_pipeline_test.mp3')...\n",
            "\tGenerating pitch increase by 5 semitones...\n",
            "\t\tSaved: outputs/complete_pipeline_test/complete_pipeline_test_pitch_up.mp3\n",
            "\n",
            "\tGenerating pitch decrease by -5 semitones...\n",
            "\t\tSaved: outputs/complete_pipeline_test/complete_pipeline_test_pitch_down.mp3\n",
            "\n",
            "\tGenerating increased speed by factor of 2.0...\n",
            "\t\tSaved: outputs/complete_pipeline_test/complete_pipeline_test_speed_up.mp3\n",
            "\n",
            "\tGenerating reverb (room size: 0.7)...\n",
            "\t\tSaved: outputs/complete_pipeline_test/complete_pipeline_test_reverb.mp3\n",
            "\n",
            "Done! All files saved to: outputs/complete_pipeline_test\n",
            "\n",
            "\n",
            "✓ Complete pipeline finished successfully!\n"
          ]
        }
      ],
      "source": [
        "# Chain both pipelines together\n",
        "print(\"STEP 1: Converting text to audio...\")\n",
        "\n",
        "text = \"The quick brown fox jumps over the lazy dog. This is a test of the audio processing pipeline.\"\n",
        "audio_path = text_pipeline.convert(text, \"complete_pipeline_test\")\n",
        "\n",
        "print(\"\\nSTEP 2: Applying audio effects...\")\n",
        "\n",
        "if audio_path:\n",
        "    audio_pipeline.process(\n",
        "        str(audio_path),\n",
        "        pitch_increase=5,\n",
        "        pitch_decrease=-5,\n",
        "        speed_increase=2.0,\n",
        "        reverb_room_size=0.7\n",
        "    )\n",
        "    print(\"\\n✓ Complete pipeline finished successfully!\")\n",
        "else:\n",
        "    print(\"Failed to generate audio file.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wObY4UjgCbtj"
      },
      "source": [
        "---\n",
        "## Example 7: End-to-End Pipeline\n",
        "**HuggingFace Text Data → Audio Generation → Audio Permutation Generation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "0vvajURgCbtj",
        "outputId": "3b217409-2465-425d-f3a2-cfd9ee0ffe0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 1: Retrieve Text Data ...\n",
            "Cell Index [5, 'question']:\n",
            "Which of the following is the body cavity that contains the pituitary gland?...\n",
            "\n",
            "STEP 2: Generate Base Audio ...\n",
            "Processing: 'e2e_output'...\n",
            "\t[✓] Transcript: /content/outputs/e2e_output.txt\n",
            "\t[✓] Audio:      /content/outputs/e2e_output.mp3\n",
            "\n",
            "STEP 3: Applying Audio Effects ...\n",
            "Copying input file to output directory...\n",
            "\tCopied to: outputs/e2e_output/e2e_output.mp3\n",
            "\n",
            "Loading audio file ('outputs/e2e_output.mp3')...\n",
            "\tGenerating pitch increase by 5 semitones...\n",
            "\t\tSaved: outputs/e2e_output/e2e_output_pitch_up.mp3\n",
            "\n",
            "\tGenerating pitch decrease by -5 semitones...\n",
            "\t\tSaved: outputs/e2e_output/e2e_output_pitch_down.mp3\n",
            "\n",
            "\tGenerating increased speed by factor of 2.0...\n",
            "\t\tSaved: outputs/e2e_output/e2e_output_speed_up.mp3\n",
            "\n",
            "\tGenerating reverb (room size: 0.7)...\n",
            "\t\tSaved: outputs/e2e_output/e2e_output_reverb.mp3\n",
            "\n",
            "Done! All files saved to: outputs/e2e_output\n",
            "\n",
            "\n",
            "✓ End-to-end pipeline finished successfully!\n"
          ]
        }
      ],
      "source": [
        "print(\"STEP 1: Retrieve Text Data ...\")\n",
        "\n",
        "question_5 = indexer.get_cell(5, \"question\")\n",
        "print(f\"Cell Index [5, 'question']:\\n{question_5[:100]}...\\n\")\n",
        "\n",
        "print(\"STEP 2: Generate Base Audio ...\")\n",
        "\n",
        "audio_path = text_pipeline.convert(question_5, \"e2e_output\")\n",
        "\n",
        "print(\"STEP 3: Applying Audio Effects ...\")\n",
        "\n",
        "if audio_path:\n",
        "    audio_pipeline.process(\n",
        "        str(audio_path),\n",
        "        pitch_increase=5,\n",
        "        pitch_decrease=-5,\n",
        "        speed_increase=2.0,\n",
        "        reverb_room_size=0.7\n",
        "    )\n",
        "    print(\"\\n✓ End-to-end pipeline finished successfully!\")\n",
        "else:\n",
        "    print(\"Failed to generate audio file.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ka39B3x2Cbtj"
      },
      "source": [
        "---\n",
        "## Summary\n",
        "\n",
        "Complete audio processing pipeline:\n",
        "\n",
        "**Available Classes:**\n",
        "- `HFDataIndexer`: Lazy-load data from HuggingFace datasets\n",
        "- `TextToAudioPipeline`: Convert text to MP3 files with transcripts\n",
        "- `AudioPermutationPipeline`: Apply audio effects (pitch, speed, reverb)\n",
        "\n",
        "**Key Features:**\n",
        "- Streaming HuggingFace datasets\n",
        "- Create audio files + add audio effects (pitch, speed, reverd)\n",
        "- Full end-to-end pipeline integration\n",
        "\n",
        "All generated files are saved to `./outputs/` by default."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "cIN6pzd5CmC3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prototyping saving data to google drive here"
      ],
      "metadata": {
        "id": "VC1VTcnECnX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import gspread\n",
        "# from google.colab import auth\n",
        "# from google.auth import default\n",
        "# from googleapiclient.discovery import build\n",
        "# from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "# def export_ml_data(sheet_link, drive_parent_folder_id, data_array):\n",
        "#     \"\"\"\n",
        "#     Processes an array of data, creates public Drive folders/files, and logs to Sheets.\n",
        "#     data_array format: [[page_name, question_id, file_name, local_file_path], ...]\n",
        "#     \"\"\"\n",
        "\n",
        "#     # 1. Authenticate the Colab user (This will trigger a popup in Colab)\n",
        "#     print(\"Authenticating user...\")\n",
        "#     auth.authenticate_user()\n",
        "#     creds, _ = default()\n",
        "\n",
        "#     # 2. Initialize Google Drive and Sheets APIs\n",
        "#     gc = gspread.authorize(creds)\n",
        "#     drive_service = build('drive', 'v3', credentials=creds)\n",
        "\n",
        "#     # 3. Open the Google Sheet\n",
        "#     try:\n",
        "#         sheet = gc.open_by_url(sheet_link)\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error opening Google Sheet: {e}\")\n",
        "#         return\n",
        "\n",
        "#     # 4. Loop through the array items\n",
        "#     for item in data_array:\n",
        "#         page_name, question_id, file_name, local_file_path = item\n",
        "#         print(f\"\\nProcessing Question ID: {question_id}...\")\n",
        "\n",
        "#         # --- GOOGLE DRIVE OPERATIONS ---\n",
        "\n",
        "#         # Step 1: Create a new folder named after the question_id\n",
        "#         folder_metadata = {\n",
        "#             'name': str(question_id),\n",
        "#             'mimeType': 'application/vnd.google-apps.folder',\n",
        "#             'parents': [drive_parent_folder_id]\n",
        "#         }\n",
        "#         folder = drive_service.files().create(body=folder_metadata, fields='id').execute()\n",
        "#         folder_id = folder.get('id')\n",
        "\n",
        "#         # Make the folder publicly viewable\n",
        "#         permission = {'type': 'anyone', 'role': 'reader'}\n",
        "#         drive_service.permissions().create(fileId=folder_id, body=permission).execute()\n",
        "\n",
        "#         # Step 2: Upload the local file into the new folder\n",
        "#         file_metadata = {\n",
        "#             'name': file_name,\n",
        "#             'parents': [folder_id]\n",
        "#         }\n",
        "#         media = MediaFileUpload(local_file_path, resumable=True)\n",
        "#         uploaded_file = drive_service.files().create(\n",
        "#             body=file_metadata,\n",
        "#             media_body=media,\n",
        "#             fields='id, webViewLink'\n",
        "#         ).execute()\n",
        "\n",
        "#         file_id = uploaded_file.get('id')\n",
        "#         file_url = uploaded_file.get('webViewLink')\n",
        "\n",
        "#         # Make the uploaded file publicly viewable\n",
        "#         drive_service.permissions().create(fileId=file_id, body=permission).execute()\n",
        "\n",
        "#         # --- GOOGLE SHEETS OPERATIONS ---\n",
        "\n",
        "#         # Step 3: Navigate to the specified page (worksheet)\n",
        "#         try:\n",
        "#             worksheet = sheet.worksheet(page_name)\n",
        "#         except gspread.exceptions.WorksheetNotFound:\n",
        "#             print(f\"Worksheet '{page_name}' not found. Skipping {question_id}.\")\n",
        "#             continue\n",
        "\n",
        "#         # Step 4: Calculate the new incremented row ID and append the data\n",
        "#         col_1_values = worksheet.col_values(1)\n",
        "\n",
        "#         # Grab the last row's ID. If it's text (like a header) or empty, default to 0.\n",
        "#         try:\n",
        "#             last_id = int(col_1_values[-1])\n",
        "#         except (ValueError, IndexError):\n",
        "#             last_id = 0\n",
        "\n",
        "#         new_id = last_id + 1\n",
        "\n",
        "#         # Append the new row to the first empty row automatically\n",
        "#         # Column 1: ID | Column 2: Question ID | Column 3: Public File Link\n",
        "#         worksheet.append_row([new_id, question_id, file_url])\n",
        "\n",
        "#         print(f\"Successfully uploaded and logged {file_name} to sheet '{page_name}'.\")\n",
        "\n",
        "# # Example Usage:\n",
        "# upload_details_1 = [\n",
        "#     [\"original\", \"0\", \"0_original.mp3\", \"/content/outputs/sample_output/sample_output.mp3\"],\n",
        "#     [\"busy_street\", \"0\", \"0_busy_street.mp3\", \"/content/outputs/sample_output/sample_output_overlay_busy_street.mp3\"],\n",
        "# ]\n",
        "# upload_details_2 = [\n",
        "#     [\"original\", \"1\", \"1_original.mp3\", \"/content/outputs/sample_output/sample_output_speed_up.mp3\"],\n",
        "#     [\"busy_street\", \"1\", \"1_busy_street.mp3\", \"/content/outputs/sample_output/sample_output_speed_down.mp3\"],\n",
        "# ]\n",
        "# upload_details_3 = [\n",
        "#     [\"original\", \"2\", \"2_original.mp3\", \"/content/outputs/sample_output/sample_output_pitch_up.mp3\"],\n",
        "#     [\"busy_street\", \"2\", \"2_busy_street.mp3\", \"/content/outputs/sample_output/sample_output_pitch_down.mp3\"]\n",
        "# ]\n",
        "\n",
        "# sheet_link = \"https://docs.google.com/spreadsheets/d/1tZ-eaQqtb-tbzn9YVdqo7cEg80UxD_DP737HNdAJfbI/edit?gid=293340750#gid=293340750\"\n",
        "# drive_parent_id = \"1FQjh0-DBKC0iettweDAs9bfLI2B3NoDe\"\n",
        "# for upload_detail in [upload_details_1, upload_details_2, upload_details_3]:\n",
        "#   export_ml_data(sheet_link, drive_parent_id, upload_detail)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#\n",
        "#\n",
        "#\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "def export_ml_data(sheet_link, drive_parent_folder_id, data_array):\n",
        "    print(\"Authenticating user...\")\n",
        "    auth.authenticate_user()\n",
        "    creds, _ = default()\n",
        "\n",
        "    gc = gspread.authorize(creds)\n",
        "    drive_service = build('drive', 'v3', credentials=creds)\n",
        "\n",
        "    try:\n",
        "        sheet = gc.open_by_url(sheet_link)\n",
        "    except Exception as e:\n",
        "        print(f\"Error opening Google Sheet: {e}\")\n",
        "        return\n",
        "\n",
        "    # Step 1: Create Folder (No permission changes here!)\n",
        "    folder_metadata = {\n",
        "        'name': str(data_array[0][1]),\n",
        "        'mimeType': 'application/vnd.google-apps.folder',\n",
        "        'parents': [drive_parent_folder_id]\n",
        "    }\n",
        "    folder = drive_service.files().create(body=folder_metadata, fields='id').execute()\n",
        "    folder_id = folder.get('id')\n",
        "\n",
        "    for item in data_array:\n",
        "        page_name, question_id, file_name, local_file_path = item\n",
        "        print(f\"\\nProcessing Question ID: {question_id}...\")\n",
        "\n",
        "        # --- GOOGLE DRIVE OPERATIONS ---\n",
        "\n",
        "        # Step 2: Upload File (No permission changes here either!)\n",
        "        file_metadata = {\n",
        "            'name': file_name,\n",
        "            'parents': [folder_id]\n",
        "        }\n",
        "        media = MediaFileUpload(local_file_path, resumable=True)\n",
        "        uploaded_file = drive_service.files().create(\n",
        "            body=file_metadata,\n",
        "            media_body=media,\n",
        "            fields='id, webViewLink'\n",
        "        ).execute()\n",
        "\n",
        "        file_url = uploaded_file.get('webViewLink')\n",
        "\n",
        "        # --- GOOGLE SHEETS OPERATIONS ---\n",
        "\n",
        "        # Step 3: Connect to Worksheet\n",
        "        try:\n",
        "            worksheet = sheet.worksheet(page_name)\n",
        "        except gspread.exceptions.WorksheetNotFound:\n",
        "            print(f\"Worksheet '{page_name}' not found. Skipping {question_id}.\")\n",
        "            continue\n",
        "\n",
        "        # Step 4: Calculate ID and Append Row\n",
        "        # col_1_values = worksheet.col_values(1)\n",
        "\n",
        "        # try:\n",
        "        #     last_id = int(col_1_values[-1])\n",
        "        # except (ValueError, IndexError):\n",
        "        #     last_id = 0\n",
        "\n",
        "        # new_id = last_id + 1\n",
        "\n",
        "        # worksheet.append_row([new_id, question_id, file_url])\n",
        "        # col_1_values = worksheet.col_values(1)\n",
        "\n",
        "        # try:\n",
        "        #     last_id = int(col_1_values[-1])\n",
        "        # except (ValueError, IndexError):\n",
        "        #     last_id = 0\n",
        "\n",
        "        # new_id = last_id + 1\n",
        "\n",
        "        worksheet.append_row([question_id, file_url])\n",
        "\n",
        "        print(f\"Successfully uploaded and logged {file_name} to sheet '{page_name}'.\")\n",
        "\n",
        "# Example Usage:\n",
        "upload_details_1 = [\n",
        "    [\"original\", \"0\", \"0_original.mp3\", \"/content/outputs/sample_output/sample_output.mp3\"],\n",
        "    [\"busy_street\", \"0\", \"0_busy_street.mp3\", \"/content/outputs/sample_output/sample_output_overlay_busy_street.mp3\"],\n",
        "]\n",
        "upload_details_2 = [\n",
        "    [\"original\", \"1\", \"1_original.mp3\", \"/content/outputs/sample_output/sample_output_speed_up.mp3\"],\n",
        "    [\"busy_street\", \"1\", \"1_busy_street.mp3\", \"/content/outputs/sample_output/sample_output_speed_down.mp3\"],\n",
        "]\n",
        "upload_details_3 = [\n",
        "    [\"original\", \"2\", \"2_original.mp3\", \"/content/outputs/sample_output/sample_output_pitch_up.mp3\"],\n",
        "    [\"busy_street\", \"2\", \"2_busy_street.mp3\", \"/content/outputs/sample_output/sample_output_pitch_down.mp3\"]\n",
        "]\n",
        "\n",
        "sheet_link = \"https://docs.google.com/spreadsheets/d/1tZ-eaQqtb-tbzn9YVdqo7cEg80UxD_DP737HNdAJfbI/edit?gid=293340750#gid=293340750\"\n",
        "drive_parent_id = \"1FQjh0-DBKC0iettweDAs9bfLI2B3NoDe\"\n",
        "\n",
        "for upload_detail in [upload_details_1, upload_details_2, upload_details_3]:\n",
        "  export_ml_data(sheet_link, drive_parent_id, upload_detail)"
      ],
      "metadata": {
        "id": "NLfEhj8LCs9D",
        "outputId": "b059d654-375c-417a-ce06-fbc5db53d39d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authenticating user...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_auth_httplib2:httplib2 transport does not support per-request timeout. Set the timeout when constructing the httplib2.Http instance.\n",
            "WARNING:google_auth_httplib2:httplib2 transport does not support per-request timeout. Set the timeout when constructing the httplib2.Http instance.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing Question ID: 0...\n",
            "Successfully uploaded and logged 0_original.mp3 to sheet 'original'.\n",
            "\n",
            "Processing Question ID: 0...\n",
            "Successfully uploaded and logged 0_busy_street.mp3 to sheet 'busy_street'.\n",
            "Authenticating user...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_auth_httplib2:httplib2 transport does not support per-request timeout. Set the timeout when constructing the httplib2.Http instance.\n",
            "WARNING:google_auth_httplib2:httplib2 transport does not support per-request timeout. Set the timeout when constructing the httplib2.Http instance.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing Question ID: 1...\n",
            "Successfully uploaded and logged 1_original.mp3 to sheet 'original'.\n",
            "\n",
            "Processing Question ID: 1...\n",
            "Successfully uploaded and logged 1_busy_street.mp3 to sheet 'busy_street'.\n",
            "Authenticating user...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_auth_httplib2:httplib2 transport does not support per-request timeout. Set the timeout when constructing the httplib2.Http instance.\n",
            "WARNING:google_auth_httplib2:httplib2 transport does not support per-request timeout. Set the timeout when constructing the httplib2.Http instance.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing Question ID: 2...\n",
            "Successfully uploaded and logged 2_original.mp3 to sheet 'original'.\n",
            "\n",
            "Processing Question ID: 2...\n",
            "Successfully uploaded and logged 2_busy_street.mp3 to sheet 'busy_street'.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}